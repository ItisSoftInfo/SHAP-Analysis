{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03daf8c3",
   "metadata": {},
   "source": [
    "Before starting SHAP Analysis you need to install the following:\n",
    "1. Python\n",
    "2. Anaconda Navigator.\n",
    "3. Install required liberaries.\n",
    "\n",
    "For installing liberaries:\n",
    "\n",
    "Open \"Anaconda Prompt\" as Administrator and Run the following commands:\n",
    "\n",
    "command 1: pip3 install xgboost\n",
    "\n",
    "command 2: pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4506c",
   "metadata": {},
   "source": [
    "# Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7462da",
   "metadata": {},
   "source": [
    "# For loading and previewing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c8384",
   "metadata": {},
   "source": [
    "1. We are reading data from a .csv file.\n",
    "2. If you don't have a .csv file of data, first create one.\n",
    "3. Place the .csv file in the folder where you created your Python file.\n",
    "4. In our case it is \"Downloads\\Untitled Folder\".\n",
    "5. The \"SHAP.csv\" is the name of .csv file created in \"Step 2\".\n",
    "6. The name of file and this should be same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b79901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SHAP.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2e145",
   "metadata": {},
   "source": [
    "# Viewing summary of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad108c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb366aa",
   "metadata": {},
   "source": [
    "# Declaring \"X\" and \"Y\" values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a3da5",
   "metadata": {},
   "source": [
    "Make sure the names of variables are same both in code and in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['A','B','C','D','E','F','G','H']]\n",
    "\n",
    "y = df['Model Values']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e5501",
   "metadata": {},
   "source": [
    "# Splitting the data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386a7b0",
   "metadata": {},
   "source": [
    "# Building the model with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1f0cc",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eda5dd",
   "metadata": {},
   "source": [
    "# Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee869a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)**(0.5)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740f4ae",
   "metadata": {},
   "source": [
    "# Explaining the model's predictions using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3883c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44d421",
   "metadata": {},
   "source": [
    "# Visualizing the first prediction's explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3de907",
   "metadata": {},
   "source": [
    "This plot shows each feature contributing to push the model output from the base value (the average model output over the training dataset) \n",
    "to the model output.\n",
    "Features pushing the prediction higher are shown in red and those pushing the prediction lower are in blue.\n",
    "\n",
    "So, E, G, and H pushes the prediction higher and D, B, A, and F pushes the prediction lower.\n",
    "\n",
    "The base value of the \"Model Value\" is 579.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8647d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ba51b",
   "metadata": {},
   "source": [
    "# Visualizing the training set predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad44b5",
   "metadata": {},
   "source": [
    "The following plot is interactive. Just scroll the mouse and see the different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa7b69",
   "metadata": {},
   "source": [
    "# Standard way of plotting feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615bdbd3",
   "metadata": {},
   "source": [
    "To visualize the SHAP feature importance for a trained random forest model, the features are sorted in decreasing order of importance and plotted accordingly. The resulting plot displays the mean absolute Shapley values.\n",
    "\n",
    "In the specific figure presented, the variable \"H\" is identified as the most important feature.\n",
    "\n",
    "This code automatically saves the picture in parent folder with the defined name in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f952e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(model).shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, show=False, plot_type=\"bar\")\n",
    "plt.savefig('Parameter Importance.JPG', dpi=300, bbox_inches ='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61a293",
   "metadata": {},
   "source": [
    "# Summary plot combining feature importance with feature effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4183649",
   "metadata": {},
   "source": [
    "The summary plot combines feature importance with feature effects. Each point on the summary plot is a Shapley value for a feature and an instance. The position on the y-axis is determined by the feature and on the x-axis by the Shapley value.\n",
    "\n",
    "The features are ordered according to their importance.\n",
    "\n",
    "This code automatically saves the picture in parent folder with the defined name in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, show=False)\n",
    "plt.savefig('Parameter Influence.JPG', dpi=300, bbox_inches ='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e59142",
   "metadata": {},
   "source": [
    "# Dependence plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b37bb5",
   "metadata": {},
   "source": [
    "A SHAP dependence plot visualizes the relationship between a feature and the model's predicted outcome. \n",
    "\n",
    "It helps identify linear or non-linear relationships and interactions with other features.\n",
    "\n",
    "The automatically selects the variable that has the strongest interaction with the chosen variable, providing insight into how their combined effect affects the predicted outcome.\n",
    "\n",
    "This code automatically saves the picture in parent folder with the defined name in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('D', shap_values, X_train, show=False)\n",
    "plt.savefig('D Dependence.JPG', dpi=300, bbox_inches ='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('E', shap_values, X_train, show=False)\n",
    "plt.savefig('E Dependence.JPG', dpi=300, bbox_inches ='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d2847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
